/*
 * Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT.
 */

import { routerCreate } from "../funcs/routerCreate.js";
import { routerCreateStreaming } from "../funcs/routerCreateStreaming.js";
import { routerDeleteChatCompletion } from "../funcs/routerDeleteChatCompletion.js";
import { routerGetChatCompletion } from "../funcs/routerGetChatCompletion.js";
import { routerGetChatCompletionMessages } from "../funcs/routerGetChatCompletionMessages.js";
import { routerListChatCompletions } from "../funcs/routerListChatCompletions.js";
import { routerUpdateChatCompletion } from "../funcs/routerUpdateChatCompletion.js";
import { EventStream } from "../lib/event-streams.js";
import { ClientSDK, RequestOptions } from "../lib/sdks.js";
import * as models from "../models/index.js";
import * as operations from "../models/operations/index.js";
import { unwrapAsync } from "../types/fp.js";

export class Router extends ClientSDK {
  /**
   * *[OpenAI Only]* Get a list of saved Chat Completions. Only Chat Completions that have been stored with the `store` parameter set to true will be returned.
   */
  async listChatCompletions(
    request?: operations.ListChatCompletionsRequest | undefined,
    options?: RequestOptions,
  ): Promise<models.ChatCompletionList> {
    return unwrapAsync(routerListChatCompletions(
      this,
      request,
      options,
    ));
  }

  /**
   * Create a model response for the given string of prompts.
   */
  async create(
    request: models.ChatCompletionRequestJson,
    options?: RequestOptions,
  ): Promise<models.ChatCompletion> {
    return unwrapAsync(routerCreate(
      this,
      request,
      options,
    ));
  }

  /**
   * Create a streaming model response for the given string of prompts using server-sent events.
   */
  async createStreaming(
    request: models.ChatCompletionRequestStream,
    options?: RequestOptions,
  ): Promise<EventStream<models.ChatCompletionChunk>> {
    return unwrapAsync(routerCreateStreaming(
      this,
      request,
      options,
    ));
  }

  /**
   * *[OpenAI Only]* Get a Chat Completion. Only Chat Completions that have been stored with the `store` parameter set to true will be returned.
   */
  async getChatCompletion(
    request: operations.GetChatCompletionRequest,
    options?: RequestOptions,
  ): Promise<models.ChatCompletion> {
    return unwrapAsync(routerGetChatCompletion(
      this,
      request,
      options,
    ));
  }

  /**
   * *[OpenAI Only]* Update a Chat Completion with some metadata. Only Chat Completions that have been stored with the `store` parameter set to true will be returned.
   */
  async updateChatCompletion(
    request: operations.UpdateChatCompletionRequest,
    options?: RequestOptions,
  ): Promise<models.ChatCompletion> {
    return unwrapAsync(routerUpdateChatCompletion(
      this,
      request,
      options,
    ));
  }

  /**
   * *[OpenAI Only]* Delete a stored Chat Completion. Only Chat Completions that have been stored with the `store` parameter set to true will be returned.
   */
  async deleteChatCompletion(
    request: operations.DeleteChatCompletionRequest,
    options?: RequestOptions,
  ): Promise<models.ChatDeletionConfirmation> {
    return unwrapAsync(routerDeleteChatCompletion(
      this,
      request,
      options,
    ));
  }

  /**
   * *[OpenAI Only]* Get the array of messages for a saved Chat Completion. Only Chat Completions that have been stored with the `store` parameter set to true will be returned.
   */
  async getChatCompletionMessages(
    request: operations.GetChatCompletionMessagesRequest,
    options?: RequestOptions,
  ): Promise<models.ChatMessageList> {
    return unwrapAsync(routerGetChatCompletionMessages(
      this,
      request,
      options,
    ));
  }
}
